import { Component } from '@angular/core';
import { CommonModule } from '@angular/common';
import { RouterModule } from '@angular/router';
import { MatCardModule } from '@angular/material/card';
import { MatIconModule } from '@angular/material/icon';
import { MatExpansionModule } from '@angular/material/expansion';
import { MatDividerModule } from '@angular/material/divider';
import { MatButtonModule } from '@angular/material/button';
import { MatTooltipModule } from '@angular/material/tooltip';

@Component({
  selector: 'app-knowledge',
  standalone: true,
  imports: [
    CommonModule,
    RouterModule,
    MatCardModule,
    MatIconModule,
    MatExpansionModule,
    MatDividerModule,
    MatButtonModule,
    MatTooltipModule
  ],
  templateUrl: './knowledge.component.html',
  styleUrl: './knowledge.component.scss'
})
export class KnowledgeComponent {
  // مفاهیم مربوط به LLM
  llmConcepts = [
    {
      title: 'مدل زبان بزرگ (LLM)',
      icon: 'psychology',
      description: 'مدل‌های زبان بزرگ (Large Language Models) الگوریتم‌های هوش مصنوعی هستند که با استفاده از میلیاردها پارامتر و آموزش روی حجم عظیمی از داده‌های متنی، قادر به درک و تولید متن به شکلی شبیه به انسان هستند. این مدل‌ها می‌توانند وظایف مختلفی مانند پاسخ به سؤالات، خلاصه‌سازی متون، ترجمه، و تولید محتوا را انجام دهند.',
      details: [
        'مدل‌های زبان بزرگ با استفاده از معماری ترانسفورمر (Transformer) ساخته می‌شوند که به آن‌ها اجازه می‌دهد ارتباطات پیچیده بین کلمات و مفاهیم را درک کنند.',
        'این مدل‌ها با روش یادگیری عمیق (Deep Learning) آموزش می‌بینند و می‌توانند الگوهای پیچیده را در داده‌های زبانی تشخیص دهند.',
        'نمونه‌های معروف LLM شامل GPT (از OpenAI)، LLaMA (از Meta)، Claude (از Anthropic) و Gemini (از Google) می‌شوند.'
      ]
    },
    {
      title: 'ارائه‌دهنده API',
      icon: 'cloud',
      description: 'ارائه‌دهندگان API سرویس‌هایی هستند که دسترسی به مدل‌های زبان بزرگ را از طریق رابط برنامه‌نویسی (API) فراهم می‌کنند. این سرویس‌ها امکان استفاده از قدرت LLM‌ها را بدون نیاز به منابع محاسباتی گسترده و دانش تخصصی عمیق فراهم می‌کنند.',
      details: [
        'OpenAI: ارائه‌دهنده مدل‌های GPT با API‌های قدرتمند برای کاربردهای مختلف',
        'OpenRouter: یک سرویس واسط که دسترسی به طیف وسیعی از مدل‌های مختلف را از طریق یک API واحد فراهم می‌کند',
        'برای استفاده از این سرویس‌ها نیاز به کلید API دارید که باید در تنظیمات سیستم وارد شود'
      ]
    },
    {
      title: 'دما (Temperature)',
      icon: 'thermostat',
      description: 'دما یک پارامتر تنظیمی در مدل‌های زبان است که میزان خلاقیت و تصادفی بودن پاسخ‌های تولید شده را کنترل می‌کند. مقادیر بالاتر منجر به پاسخ‌های متنوع‌تر و خلاقانه‌تر می‌شود، در حالی که مقادیر پایین‌تر پاسخ‌های قطعی‌تر و قابل پیش‌بینی‌تری تولید می‌کنند.',
      details: [
        'محدوده معمول: 0.0 تا 2.0',
        'دمای پایین (0.0-0.3): مناسب برای کاربردهایی که نیاز به دقت بالا و پاسخ‌های قطعی دارند، مانند پاسخ به سؤالات واقعی یا استخراج اطلاعات',
        'دمای متوسط (0.3-0.7): تعادلی بین خلاقیت و دقت، مناسب برای بیشتر کاربردها',
        'دمای بالا (0.7-2.0): مناسب برای تولید محتوای خلاقانه، ایده‌پردازی، یا شبیه‌سازی مکالمات متنوع'
      ]
    },
    {
      title: 'Top P (هسته احتمالی)',
      icon: 'bar_chart',
      description: 'Top P یا نمونه‌برداری هسته احتمالی (Nucleus Sampling) روشی برای کنترل تنوع خروجی مدل است. این پارامتر تعیین می‌کند که مدل فقط از کلماتی با بالاترین احتمال تجمعی تا سقف P انتخاب کند. این روش به مدل اجازه می‌دهد کلمات نامحتمل را نادیده بگیرد اما همچنان تنوع معقولی در پاسخ‌ها داشته باشد.',
      details: [
        'محدوده: 0.0 تا 1.0',
        'مقادیر پایین‌تر (مثلاً 0.1) باعث می‌شود مدل فقط محتمل‌ترین کلمات را انتخاب کند',
        'مقادیر بالاتر (مثلاً 0.9) به مدل اجازه می‌دهد از طیف وسیع‌تری از کلمات استفاده کند',
        'تنظیم معمول و متعادل: 0.7 تا 0.9'
      ]
    },
    {
      title: 'حداکثر توکن',
      icon: 'text_fields',
      description: 'حداکثر توکن تعیین می‌کند که مدل حداکثر چند توکن (واحدهای متنی) می‌تواند در پاسخ تولید کند. هر توکن معمولاً معادل حدود 4 کاراکتر یا 0.75 کلمه در زبان انگلیسی است. تنظیم این پارامتر به کنترل طول پاسخ‌های دریافتی کمک می‌کند.',
      details: [
        'محدوده معمول: 1 تا 4096 (بسته به مدل می‌تواند متفاوت باشد)',
        'تنظیم این پارامتر بر اساس نیاز کاربردی شما انجام می‌شود',
        'مقادیر بالاتر برای پاسخ‌های طولانی‌تر و جامع‌تر مناسب است',
        'مقادیر پایین‌تر برای پاسخ‌های کوتاه و مختصر مناسب است'
      ]
    },
    {
      title: 'مدل Embedding',
      icon: 'scatter_plot',
      description: 'مدل Embedding الگوریتمی است که متن را به بردارهای عددی (وکتورها) تبدیل می‌کند. این بردارها نمایش ریاضی معنای متن هستند و به سیستم اجازه می‌دهند تا شباهت معنایی بین متون مختلف را محاسبه کند. این قابلیت برای جستجوی معنایی در پایگاه دانش ضروری است.',
      details: [
        'مدل‌های Embedding متن را به فضای برداری چند بعدی نگاشت می‌کنند که در آن متون با معانی مشابه به یکدیگر نزدیک هستند',
        'این مدل‌ها برای عملیات جستجو در سیستم RAG استفاده می‌شوند',
        'مدل پیش‌فرض در OpenAI: text-embedding-ada-002',
        'کیفیت مدل Embedding تأثیر مستقیمی بر دقت بازیابی اطلاعات مرتبط دارد'
      ]
    }
  ];

  // مفاهیم مربوط به RAG
  ragConcepts = [
    {
      title: 'بازیابی و تولید تقویت شده (RAG)',
      icon: 'auto_awesome',
      description: 'RAG (Retrieval-Augmented Generation) یک روش ترکیبی است که قابلیت‌های بازیابی اطلاعات را با تولید متن توسط مدل‌های زبان بزرگ ادغام می‌کند. این سیستم ابتدا اطلاعات مرتبط را از یک پایگاه دانش بازیابی می‌کند و سپس از آن برای تقویت پاسخ‌های مدل زبان استفاده می‌کند.',
      details: [
        'RAG به مدل‌های زبان اجازه می‌دهد به جای تکیه صرف بر دانش داخلی خود، از منابع خارجی اطلاعات استفاده کنند',
        'این روش دقت پاسخ‌ها را افزایش می‌دهد و خطر تولید اطلاعات نادرست (توهم هوش مصنوعی) را کاهش می‌دهد',
        'RAG به‌روزرسانی دانش مدل بدون نیاز به آموزش مجدد کامل را امکان‌پذیر می‌سازد',
        'این سیستم برای کاربردهایی که نیاز به اطلاعات دقیق و به‌روز دارند، مانند پشتیبانی مشتری یا سیستم‌های پاسخگویی به سؤالات تخصصی، ایده‌آل است'
      ]
    },
    {
      title: 'آستانه اطمینان پایگاه دانش',
      icon: 'trending_up',
      description: 'آستانه اطمینان پایگاه دانش تعیین می‌کند که سیستم با چه میزان اطمینانی باید از اطلاعات بازیابی شده از پایگاه دانش استفاده کند. اگر میزان اطمینان به نتایج جستجو کمتر از این آستانه باشد، سیستم ممکن است به جای استفاده از پایگاه دانش، به دانش داخلی مدل زبان تکیه کند یا کاربر را به کارشناس انسانی ارجاع دهد.',
      details: [
        'محدوده: 0.0 تا 1.0',
        'مقادیر بالاتر (مثلاً 0.8) باعث می‌شود سیستم فقط زمانی از پایگاه دانش استفاده کند که اطمینان بالایی به مرتبط بودن نتایج داشته باشد',
        'مقادیر پایین‌تر (مثلاً 0.5) اجازه می‌دهد سیستم از نتایج با ارتباط کمتر نیز استفاده کند',
        'تنظیم معمول و متعادل: 0.7'
      ]
    },
    {
      title: 'آستانه تطبیق سوال و جواب',
      icon: 'question_answer',
      description: 'این پارامتر تعیین می‌کند که سیستم با چه میزان اطمینانی باید یک سؤال ورودی را با سؤالات موجود در پایگاه دانش تطبیق دهد. اگر میزان تطبیق بالاتر از این آستانه باشد، سیستم می‌تواند مستقیماً از پاسخ‌های آماده استفاده کند.',
      details: [
        'محدوده: 0.0 تا 1.0',
        'مقادیر بالاتر (مثلاً 0.8) نیاز به تطبیق دقیق‌تر بین سؤال ورودی و سؤالات موجود در پایگاه دانش دارد',
        'مقادیر پایین‌تر (مثلاً 0.5) اجازه می‌دهد سیستم از پاسخ‌های آماده برای سؤالات مشابه (نه لزوماً یکسان) استفاده کند',
        'تنظیم معمول و متعادل: 0.6'
      ]
    },
    {
      title: 'ضریب اولویت سوال و جواب',
      icon: 'priority_high',
      description: 'این پارامتر تعیین می‌کند که سیستم چقدر به جفت‌های سؤال و جواب از پیش تعریف شده در مقایسه با اطلاعات عمومی بازیابی شده از پایگاه دانش اولویت دهد. مقادیر بالاتر باعث می‌شود سیستم تمایل بیشتری به استفاده از پاسخ‌های آماده داشته باشد.',
      details: [
        'محدوده معمول: 1.0 تا 5.0',
        'مقدار 1.0 به معنای عدم اولویت‌دهی خاص به جفت‌های سؤال و جواب است',
        'مقادیر بالاتر (مثلاً 3.0) باعث می‌شود سیستم ترجیح قوی‌تری برای استفاده از پاسخ‌های آماده داشته باشد',
        'این پارامتر برای سیستم‌هایی که دارای پایگاه داده سؤال و جواب با کیفیت بالا هستند، مفید است'
      ]
    },
    {
      title: 'نوع جستجو',
      icon: 'search',
      description: 'نوع جستجو الگوریتمی را که سیستم برای بازیابی اطلاعات مرتبط از پایگاه دانش استفاده می‌کند، تعیین می‌کند. هر الگوریتم مزایا و معایب خاص خود را دارد و انتخاب مناسب به نوع داده‌ها و نیازهای خاص شما بستگی دارد.',
      details: [
        'شباهت (Similarity): ساده‌ترین روش که اسناد را بر اساس شباهت معنایی با پرسش کاربر رتبه‌بندی می‌کند',
        'حداکثر تنوع حاشیه‌ای (MMR): تعادلی بین ارتباط و تنوع ایجاد می‌کند تا از بازیابی اسناد بسیار مشابه به یکدیگر جلوگیری شود',
        'آستانه امتیاز شباهت: فقط اسنادی را بازیابی می‌کند که امتیاز شباهت آنها از یک آستانه مشخص بالاتر باشد'
      ]
    },
    {
      title: 'تعداد نتایج برتر (Top K)',
      icon: 'filter_list',
      description: 'این پارامتر تعیین می‌کند که سیستم چند سند یا قطعه اطلاعات را از پایگاه دانش بازیابی کند و برای تولید پاسخ در اختیار مدل زبان قرار دهد. تعداد بهینه به پیچیدگی سؤالات و ماهیت پایگاه دانش بستگی دارد.',
      details: [
        'محدوده معمول: 1 تا 20',
        'مقادیر پایین‌تر (مثلاً 3-5) برای سؤالات ساده یا زمانی که دقت بسیار مهم است، مناسب هستند',
        'مقادیر بالاتر (مثلاً 8-15) برای سؤالات پیچیده که ممکن است به اطلاعات از منابع متعدد نیاز داشته باشند، مفید هستند',
        'افزایش این مقدار می‌تواند به پاسخ‌های جامع‌تر منجر شود، اما ممکن است سرعت سیستم را کاهش دهد یا باعث سردرگمی مدل شود'
      ]
    },
    {
      title: 'قالب پرامپت',
      icon: 'code',
      description: 'قالب پرامپت ساختاری است که سیستم برای ترکیب سؤال کاربر با اطلاعات بازیابی شده از پایگاه دانش استفاده می‌کند. این قالب به مدل زبان کمک می‌کند تا بداند چگونه از اطلاعات ارائه شده برای تولید پاسخ استفاده کند.',
      details: [
        'یک قالب پرامپت معمولاً شامل متغیرهایی مانند {context} برای اطلاعات بازیابی شده و {question} برای سؤال کاربر است',
        'طراحی دقیق قالب پرامپت می‌تواند تأثیر قابل توجهی بر کیفیت پاسخ‌های تولید شده داشته باشد',
        'قالب‌های خوب معمولاً شامل دستورالعمل‌های واضح برای مدل در مورد نحوه استفاده از اطلاعات و فرمت پاسخ هستند',
        'می‌توانید قالب را برای نیازهای خاص خود سفارشی کنید، مثلاً اضافه کردن دستورالعمل‌هایی برای ذکر منابع یا ارائه پاسخ به فرمت خاص'
      ]
    },
    {
      title: 'پرامپت سیستم',
      icon: 'tune',
      description: 'پرامپت سیستم دستورالعمل‌های کلی است که به مدل زبان می‌گوید چگونه رفتار کند و پاسخ دهد. این پرامپت شخصیت، سبک، و محدودیت‌های مدل را تعیین می‌کند و در تمام تعاملات با کاربر ثابت می‌ماند.',
      details: [
        'پرامپت سیستم می‌تواند شامل اطلاعات در مورد هویت مدل، تخصص آن، و قوانین رفتاری باشد',
        'این پرامپت می‌تواند به مدل بگوید که چه نوع محتوایی را نباید تولید کند یا چگونه با سؤالات خارج از حوزه تخصص برخورد کند',
        'طراحی دقیق پرامپت سیستم می‌تواند به بهبود کیفیت، سازگاری، و ایمنی پاسخ‌ها کمک کند',
        'می‌توانید پرامپت سیستم را برای ایجاد یک شخصیت خاص یا سبک پاسخگویی متناسب با برند خود سفارشی کنید'
      ]
    },
    {
      title: 'پیام ارجاع به کارشناس',
      icon: 'support_agent',
      description: 'این پیام زمانی نمایش داده می‌شود که سیستم تشخیص دهد نمی‌تواند به سؤال کاربر با اطمینان کافی پاسخ دهد و نیاز به ارجاع به یک کارشناس انسانی وجود دارد. طراحی مناسب این پیام می‌تواند تجربه کاربر را در این موقعیت‌ها بهبود بخشد.',
      details: [
        'پیام ارجاع باید محترمانه و شفاف باشد و دلیل عدم توانایی سیستم در پاسخگویی را توضیح دهد',
        'این پیام می‌تواند شامل اطلاعاتی در مورد فرآیند ارجاع و زمان تقریبی پاسخگویی توسط کارشناس باشد',
        'می‌توانید این پیام را برای انتقال حس اعتماد و اطمینان به کاربر سفارشی کنید',
        'یک پیام خوب می‌تواند شامل پیشنهاداتی برای سؤالات جایگزین یا منابع دیگری باشد که ممکن است به کاربر کمک کند'
      ]
    }
  ];

  // مفاهیم عمومی هوش مصنوعی
  generalConcepts = [
    {
      title: 'هوش مصنوعی (AI)',
      icon: 'smart_toy',
      description: 'هوش مصنوعی شاخه‌ای از علوم کامپیوتر است که به ایجاد سیستم‌هایی می‌پردازد که می‌توانند وظایفی را انجام دهند که معمولاً به هوش انسانی نیاز دارند. این وظایف شامل یادگیری، استدلال، حل مسئله، درک زبان، و تشخیص الگوها می‌شود.',
      details: [
        'هوش مصنوعی به دو دسته کلی تقسیم می‌شود: هوش مصنوعی ضعیف (که برای وظایف خاص طراحی شده) و هوش مصنوعی قوی (که قادر به انجام هر وظیفه فکری انسانی است)',
        'فناوری‌های هوش مصنوعی مدرن عمدتاً بر یادگیری ماشین و یادگیری عمیق متکی هستند',
        'کاربردهای هوش مصنوعی شامل پردازش زبان طبیعی، بینایی کامپیوتر، روباتیک، و سیستم‌های توصیه‌گر می‌شود'
      ]
    },
    {
      title: 'یادگیری ماشین (ML)',
      icon: 'model_training',
      description: 'یادگیری ماشین زیرمجموعه‌ای از هوش مصنوعی است که به سیستم‌ها اجازه می‌دهد از داده‌ها یاد بگیرند و عملکرد خود را بدون برنامه‌ریزی صریح بهبود دهند. این سیستم‌ها الگوها را در داده‌ها شناسایی می‌کنند و می‌توانند پیش‌بینی‌ها یا تصمیمات را بر اساس این الگوها انجام دهند.',
      details: [
        'انواع اصلی یادگیری ماشین عبارتند از: یادگیری با نظارت، یادگیری بدون نظارت، و یادگیری تقویتی',
        'یادگیری با نظارت از داده‌های برچسب‌گذاری شده استفاده می‌کند تا رابطه بین ورودی و خروجی را یاد بگیرد',
        'یادگیری بدون نظارت به دنبال کشف ساختار پنهان در داده‌های بدون برچسب است',
        'یادگیری تقویتی بر اساس سیستم پاداش و جریمه عمل می‌کند و به عامل اجازه می‌دهد رفتار بهینه را در یک محیط یاد بگیرد'
      ]
    },
    {
      title: 'یادگیری عمیق (Deep Learning)',
      icon: 'layers',
      description: 'یادگیری عمیق زیرمجموعه‌ای از یادگیری ماشین است که از شبکه‌های عصبی مصنوعی با چندین لایه (شبکه‌های عصبی عمیق) استفاده می‌کند. این روش به طور خاص در وظایفی مانند تشخیص تصویر، پردازش زبان طبیعی، و تشخیص گفتار موفق بوده است.',
      details: [
        'شبکه‌های عصبی عمیق از لایه‌های متعدد نورون‌های مصنوعی تشکیل شده‌اند که می‌توانند ویژگی‌های پیچیده و انتزاعی را از داده‌ها استخراج کنند',
        'معماری‌های مهم یادگیری عمیق شامل شبکه‌های عصبی کانولوشنی (CNN) برای پردازش تصویر و شبکه‌های عصبی بازگشتی (RNN) و ترانسفورمرها برای پردازش داده‌های توالی مانند متن می‌شوند',
        'یادگیری عمیق نیاز به حجم زیادی از داده‌های آموزشی و قدرت محاسباتی قابل توجه دارد',
        'مدل‌های زبان بزرگ (LLM) نمونه‌های پیشرفته یادگیری عمیق هستند که از معماری ترانسفورمر استفاده می‌کنند'
      ]
    },
    {
      title: 'پردازش زبان طبیعی (NLP)',
      icon: 'translate',
      description: 'پردازش زبان طبیعی شاخه‌ای از هوش مصنوعی است که به کامپیوترها توانایی درک، تفسیر، و تولید زبان انسانی را می‌دهد. این فناوری پل ارتباطی بین انسان‌ها و ماشین‌ها از طریق زبان است.',
      details: [
        'کاربردهای NLP شامل ترجمه ماشینی، خلاصه‌سازی متن، تحلیل احساسات، استخراج اطلاعات، و سیستم‌های گفتگو می‌شود',
        'فناوری‌های مدرن NLP عمدتاً بر مدل‌های یادگیری عمیق مانند ترانسفورمرها متکی هستند',
        'چالش‌های NLP شامل درک ظرافت‌های زبانی مانند کنایه، استعاره، و ابهام است',
        'پیشرفت‌های اخیر در NLP منجر به ایجاد مدل‌های زبان بزرگ شده است که می‌توانند متن شبیه به انسان تولید کنند و وظایف زبانی پیچیده را انجام دهند'
      ]
    },
    {
      title: 'پایگاه دانش (Knowledge Base)',
      icon: 'storage',
      description: 'پایگاه دانش مجموعه‌ای ساختاریافته از اطلاعات است که برای ذخیره، سازماندهی، و بازیابی دانش در یک حوزه خاص استفاده می‌شود. در سیستم RAG، پایگاه دانش منبع اطلاعاتی است که مدل زبان برای تقویت پاسخ‌های خود از آن استفاده می‌کند.',
      details: [
        'پایگاه دانش می‌تواند شامل انواع مختلفی از اسناد مانند مقالات، کتاب‌ها، راهنماها، پرسش و پاسخ‌های متداول، و گزارش‌های فنی باشد',
        'در سیستم‌های مدرن، اسناد به بردارهای عددی (embeddings) تبدیل می‌شوند که امکان جستجوی معنایی را فراهم می‌کنند',
        'یک پایگاه دانش خوب باید جامع، دقیق، به‌روز، و به خوبی سازماندهی شده باشد',
        'مدیریت و به‌روزرسانی منظم پایگاه دانش برای حفظ کارایی سیستم RAG ضروری است'
      ]
    },
    {
      title: 'پایگاه داده برداری (Vector Database)',
      icon: 'view_in_ar',
      description: 'پایگاه داده برداری نوع خاصی از پایگاه داده است که برای ذخیره و بازیابی کارآمد بردارهای عددی (embeddings) طراحی شده است. این پایگاه‌ها امکان جستجوی سریع بر اساس شباهت معنایی را فراهم می‌کنند که برای سیستم‌های RAG ضروری است.',
      details: [
        'پایگاه‌های داده برداری از الگوریتم‌های جستجوی نزدیک‌ترین همسایه تقریبی (ANN) استفاده می‌کنند تا جستجوی سریع در فضاهای بعد بالا را امکان‌پذیر سازند',
        'نمونه‌های محبوب پایگاه‌های داده برداری شامل Pinecone، Weaviate، Milvus، و Chroma می‌شوند',
        'این پایگاه‌ها می‌توانند میلیون‌ها یا حتی میلیاردها بردار را ذخیره کنند و در میلی‌ثانیه نزدیک‌ترین همسایگان را بازیابی کنند',
        'پایگاه‌های داده برداری معمولاً امکان ذخیره متادیتا همراه با بردارها را فراهم می‌کنند که برای فیلتر کردن نتایج مفید است'
      ]
    },
    {
      title: 'توهم هوش مصنوعی (AI Hallucination)',
      icon: 'psychology_alt',
      description: 'توهم هوش مصنوعی به پدیده‌ای اشاره دارد که در آن مدل‌های زبان اطلاعات نادرست یا بی‌اساسی تولید می‌کنند که در داده‌های آموزشی آنها وجود نداشته است. این یکی از چالش‌های اصلی در استفاده از مدل‌های زبان بزرگ است، به ویژه در کاربردهایی که دقت اطلاعات اهمیت زیادی دارد.',
      details: [
        'توهمات می‌توانند شامل ساخت منابع جعلی، ارائه اطلاعات نادرست، یا ادعای دانستن چیزهایی باشد که مدل نمی‌تواند بداند',
        'سیستم RAG یکی از راه‌حل‌های اصلی برای کاهش توهمات است، زیرا به مدل اجازه می‌دهد به جای تکیه بر دانش داخلی خود، از منابع خارجی معتبر استفاده کند',
        'راهکارهای دیگر برای کاهش توهمات شامل تنظیم دقیق پارامترهای مدل (مانند کاهش دما) و طراحی پرامپت‌های مناسب است',
        'ارزیابی و نظارت مداوم بر خروجی‌های مدل برای شناسایی و اصلاح توهمات ضروری است'
      ]
    }
  ];
}